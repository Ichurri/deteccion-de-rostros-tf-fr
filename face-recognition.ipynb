{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al clasificar el rostro: Exception encountered when calling Sequential.call().\n",
      "\n",
      "\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 33856, but received input with shape (1, 186624)\u001b[0m\n",
      "\n",
      "Arguments received by Sequential.call():\n",
      "  • inputs=tf.Tensor(shape=(1, 224, 224, 1), dtype=float32)\n",
      "  • training=False\n",
      "  • mask=None\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "modelo = load_model(\"modelo_rostros.h5\", compile=False)\n",
    "\n",
    "# Definir las etiquetas de las clases\n",
    "etiquetas = [\"Avl\", \"Cami\", \"Ichu\", \"Saul\"]\n",
    "\n",
    "# Cargar la imagen en la que se detectarán rostros\n",
    "ruta_imagen = \"imagen_pruieba.jpg\"  # Cambia esto por el path de tu imagen\n",
    "imagen = cv2.imread(ruta_imagen)\n",
    "rgb = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Detectar las ubicaciones de los rostros\n",
    "ubicaciones_rostros = face_recognition.face_locations(rgb)\n",
    "\n",
    "# Si no se encuentran rostros, finalizar\n",
    "if not ubicaciones_rostros:\n",
    "    print(\"No se detectaron rostros en la imagen.\")\n",
    "else:\n",
    "    # Procesar cada rostro detectado\n",
    "    for (top, right, bottom, left) in ubicaciones_rostros:\n",
    "        # Extraer el rostro de la imagen\n",
    "        rostro = rgb[top:bottom, left:right]\n",
    "\n",
    "        # Convertir el rostro a escala de grises\n",
    "        rostro = cv2.cvtColor(rostro, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Redimensionar la imagen al tamaño esperado por el modelo\n",
    "        rostro = cv2.resize(rostro, (224, 224))  # Ajustar al tamaño de entrada del modelo\n",
    "        rostro = np.expand_dims(rostro, axis=-1)  # Agregar canal para escala de grises\n",
    "        rostro = np.expand_dims(rostro, axis=0)   # Agregar dimensión para batch\n",
    "        rostro = rostro / 255.0  # Normalizar valores entre 0 y 1\n",
    "\n",
    "        # Verificar si la entrada pasa por todo el modelo convolucional\n",
    "        try:\n",
    "            prediccion = modelo.predict(rostro)  # El modelo procesa automáticamente la entrada\n",
    "            clase = np.argmax(prediccion)\n",
    "            etiqueta = etiquetas[clase]\n",
    "\n",
    "            # Dibujar la etiqueta y el rectángulo alrededor del rostro\n",
    "            cv2.rectangle(imagen, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            cv2.putText(imagen, etiqueta, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al clasificar el rostro: {e}\")\n",
    "\n",
    "    # Mostrar la imagen con las detecciones y clasificaciones\n",
    "    cv2.imshow(\"Resultados\", imagen)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
